{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A chatbot RAG playbook\n",
    "\n",
    "Get OpenAI key from `.env ` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up OpenAI model\n",
    "\n",
    "Define LLM model that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model by asking simple question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-157e6460-afa9-477e-a15e-58fa5726d584-0', usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using langchain parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elon Musk is the CEO of Tesla.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = model | output_parser\n",
    "\n",
    "chain.invoke(\"Who is the CEO of Tesla?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to text coversion\n",
    "\n",
    "Using pypdf to read pdf files and following instructions from https://python.langchain.com/docs/how_to/document_loader_pdf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'files/layout-parser-paper.pdf', 'page': 0}\n",
      "\n",
      "LayoutParser : A Uniﬁed Toolkit for Deep\n",
      "Learning Based Document Image Analysis\n",
      "Zejiang Shen1( \u0000), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\n",
      "Lee4, Jacob Carlson3, and Weining Li5\n",
      "1Allen Institute for AI\n",
      "shannons@allenai.org\n",
      "2Brown University\n",
      "ruochen zhang@brown.edu\n",
      "3Harvard University\n",
      "{melissadell,jacob carlson }@fas.harvard.edu\n",
      "4University of Washington\n",
      "bcgl@cs.washington.edu\n",
      "5University of Waterloo\n",
      "w422li@uwaterloo.ca\n",
      "Abstract. Recent advances in document image analysis (DIA) have been\n",
      "primarily driven by the application of neural networks. Ideally, research\n",
      "outcomes could be easily deployed in production and extended for further\n",
      "investigation. However, various factors like loosely organized codebases\n",
      "and sophisticated model conﬁgurations complicate the easy reuse of im-\n",
      "portant innovations by a wide audience. Though there have been on-going\n",
      "eﬀorts to improve reusability and simplify deep learning (DL) model\n",
      "development in disciplines like natural language processing and computer\n",
      "vision, none of them are optimized for challenges in the domain of DIA.\n",
      "This represents a major gap in the existing toolkit, as DIA is central to\n",
      "academic research across a wide range of disciplines in the social sciences\n",
      "and humanities. This paper introduces LayoutParser , an open-source\n",
      "library for streamlining the usage of DL in DIA research and applica-\n",
      "tions. The core LayoutParser library comes with a set of simple and\n",
      "intuitive interfaces for applying and customizing DL models for layout de-\n",
      "tection, character recognition, and many other document processing tasks.\n",
      "To promote extensibility, LayoutParser also incorporates a community\n",
      "platform for sharing both pre-trained models and full document digiti-\n",
      "zation pipelines. We demonstrate that LayoutParser is helpful for both\n",
      "lightweight and large-scale digitization pipelines in real-word use cases.\n",
      "The library is publicly available at https://layout-parser.github.io .\n",
      "Keywords: Document Image Analysis ·Deep Learning ·Layout Analysis\n",
      "·Character Recognition ·Open Source library ·Toolkit.\n",
      "1 Introduction\n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of\n",
      "document image analysis (DIA) tasks including document image classiﬁcation [ 11,arXiv:2103.15348v2  [cs.CV]  21 Jun 2021\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"files/layout-parser-paper.pdf\")\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    \n",
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting PDF text\n",
    "\n",
    "Since we can't send entire PDF as the context, we will split the PDF text in different chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "42533\n"
     ]
    }
   ],
   "source": [
    "text_document = \"\\n\".join([page.page_content for page in pages])\n",
    "print(len(pages))\n",
    "print(len(text_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "paddleOCR12usually do not come with comprehensive functionalities for other\n",
      "DIA tasks like layout analysis.\n",
      "Recent years have also seen numerous eﬀorts to create libraries for promoting\n",
      "reproducibility and reusability in the ﬁeld of DL. Libraries like Dectectron2 [ 35],\n",
      "6The number shown is obtained by specifying the search type as ‘code’.\n",
      "7https://ocr-d.de/en/about\n",
      "8https://github.com/BobLd/DocumentLayoutAnalysis\n",
      "9https://github.com/leonlulu/DeepLayout\n",
      "10https://github.com/hpanwar08/detectron2\n",
      "11https://github.com/JaidedAI/EasyOCR\n",
      "12https://github.com/PaddlePaddle/PaddleOCR\n",
      "4 Z. Shen et al.\n",
      "Efficient Data AnnotationC u s t o m i z e d  M o d e l  T r a i n i n gModel Cust omizationDI A Model HubDI A Pipeline SharingCommunity PlatformLa y out Detection ModelsDocument Images \n",
      "T h e  C o r e  L a y o u t P a r s e r  L i b r a r yOCR ModuleSt or age & VisualizationLa y out Data Structur e\n",
      "Fig. 1: The overall architecture of LayoutParser . For an input document image,\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_text(text_document)\n",
    "\n",
    "print(len(documents))\n",
    "print(documents[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prompt template\n",
    "\n",
    "Provide model some context and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain the prompt with model and the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susana'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\": \"Mary's sister is Susana\",\n",
    "    \"question\": \"Who is Mary's sister?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate OpenAI embeddings\n",
    "\n",
    "Generating embeddings for arbitary text to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n",
      "[-0.0013731546932831407, -0.034482136368751526, -0.011498215608298779, 0.0012331805191934109, -0.0261743925511837]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating embedding for different senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"Mary's sister is Susana\")\n",
    "sentence2 = embeddings.embed_query(\"Pedro's mother is a teacher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cosine similarity to calculate similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between query and sentence1: 0.9173394718348283\n",
      "Similarity between query and sentence2: 0.7680513114191245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_s1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_s2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "print(f\"Similarity between query and sentence1: {query_s1_similarity}\")\n",
    "print(f\"Similarity between query and sentence2: {query_s2_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Vector Store\n",
    "\n",
    "1. Run docker using `docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16`\n",
    "1. Connect to postgres pgvector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c1602e21-5e10-4009-8fcf-1ef2e98eace3',\n",
       " '3465c4f7-0e7d-4ef5-8483-5d1b07c68338',\n",
       " '7be06c44-7297-47b4-befe-828d2caf4c6d',\n",
       " '771d8343-49da-4b21-bcac-67a07d0a5fb9',\n",
       " '7c87704d-6c75-4aee-9ecd-694dd28d2a8e',\n",
       " 'e20d715b-e012-4531-9169-2966c4b8310e']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts([\n",
    "    \n",
    "        \"Mary's sister is Susana\",\n",
    "        \"John and Tommy are brothers\",\n",
    "        \"Patricia likes white cars\",\n",
    "        \"Pedro's mother is a teacher\",\n",
    "        \"Lucia drives an Audi\",\n",
    "        \"Mary has two siblings\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for similar content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='1567ab20-d8a5-4ab9-8a94-5631c8815e3c', metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       "  0.0826606006633015),\n",
       " (Document(id='c1602e21-5e10-4009-8fcf-1ef2e98eace3', metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       "  0.0826606006633015),\n",
       " (Document(id='937fb56e-016e-4f0c-acf5-e1efcbad3777', metadata={}, page_content='Mary has two siblings'),\n",
       "  0.09552745303019272)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using with retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1567ab20-d8a5-4ab9-8a94-5631c8815e3c', metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       " Document(id='c1602e21-5e10-4009-8fcf-1ef2e98eace3', metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       " Document(id='937fb56e-016e-4f0c-acf5-e1efcbad3777', metadata={}, page_content='Mary has two siblings')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrivier1 = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "retrivier1.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(id='df146bc4-d600-4cbd-ba28-f77d4bf1d197', metadata={}, page_content='John and Tommy are brothers'),\n",
       "  Document(id='3465c4f7-0e7d-4ef5-8483-5d1b07c68338', metadata={}, page_content='John and Tommy are brothers'),\n",
       "  Document(id='937fb56e-016e-4f0c-acf5-e1efcbad3777', metadata={}, page_content='Mary has two siblings')],\n",
       " 'question': 'Who'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(\n",
    "    context=retrivier1,\n",
    "    question = RunnablePassthrough()\n",
    ")\n",
    "\n",
    "setup.invoke(\"Who\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mary's sister is Susana.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | output_parser\n",
    "\n",
    "chain.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting the dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'files/monopoly.pdf', 'page': 0}\n",
      "\n",
      "Total pages = 8\n"
     ]
    }
   ],
   "source": [
    "# Processing pdf file\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"files/monopoly.pdf\")\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    \n",
    "print(f\"{pages[0].metadata}\\n\")\n",
    "# print(len(pages[0].page_content))\n",
    "print(f\"Total pages = {len(pages)}\")\n",
    "# print(f\"Text Sample: \\n {pages[0].page_content[:100]}\")\n",
    "# print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs = 23\n"
     ]
    }
   ],
   "source": [
    "# Splitting pages into chunks\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_documents(documents):\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    ).split_documents(documents)\n",
    "\n",
    "docs = split_documents(pages)\n",
    "\n",
    "# print(docs[0])\n",
    "print(f\"Total docs = {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating OpenAI embeddings\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vector store\n",
    "\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"  # Uses psycopg3!\n",
    "collection_name = \"monopoly_docs\"\n",
    "\n",
    "\n",
    "monopoly_vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# Adding docs to vector store\n",
    "\n",
    "d =monopoly_vector_store.add_documents(docs)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(id='03796ec7-152e-4711-a7e7-5b030e519008', metadata={'page': 1, 'source': 'files/monopoly.pdf'}, page_content='Bus: This lets you \"get off the bus early.\" Look at the two white \\ndice. You can move the value of one die, the other die, or the \\nsum of both dice. So if you rolled a 1 and a 5, you can move \\n1 space, 5 spaces, or 6 spaces: \\\\t\\'s your choice. \\nMr. Monopoly: First, move the sum of the two white dice \\nand resolve the space you land on (such as drawing a card, \\nbuying the property, paying rent, etc.). Then, one of two \\nthings will happen depending on whether or not there is still \\nproperty in the bank. \\nYES, there is property in the bank -Advance to the NEXT \\nproperty that the bank still holds and buy it if you wish. If you \\ndon\\'t want to buy this property, move to the space anyway \\nand put the property up for auction. \\nNO, there are no more properties in the bank - Advance to the \\nNOCT property on which you will owe another player money. \\nA few minor details: \\nOnly the white dice are used when determining if you rolled doubles. \\nDo not look at the Speed Die.'),\n",
       "  Document(id='04f4e750-3bc3-419f-a512-559d35d9deef', metadata={'page': 1, 'source': 'files/monopoly.pdf'}, page_content='Bus: This lets you \"get off the bus early.\" Look at the two white \\ndice. You can move the value of one die, the other die, or the \\nsum of both dice. So if you rolled a 1 and a 5, you can move \\n1 space, 5 spaces, or 6 spaces: \\\\t\\'s your choice. \\nMr. Monopoly: First, move the sum of the two white dice \\nand resolve the space you land on (such as drawing a card, \\nbuying the property, paying rent, etc.). Then, one of two \\nthings will happen depending on whether or not there is still \\nproperty in the bank. \\nYES, there is property in the bank -Advance to the NEXT \\nproperty that the bank still holds and buy it if you wish. If you \\ndon\\'t want to buy this property, move to the space anyway \\nand put the property up for auction. \\nNO, there are no more properties in the bank - Advance to the \\nNOCT property on which you will owe another player money. \\nA few minor details: \\nOnly the white dice are used when determining if you rolled doubles. \\nDo not look at the Speed Die.'),\n",
       "  Document(id='248b1334-42df-4f9f-929b-ae06a420eaae', metadata={'page': 1, 'source': 'files/monopoly.pdf'}, page_content='Bus: This lets you \"get off the bus early.\" Look at the two white \\ndice. You can move the value of one die, the other die, or the \\nsum of both dice. So if you rolled a 1 and a 5, you can move \\n1 space, 5 spaces, or 6 spaces: \\\\t\\'s your choice. \\nMr. Monopoly: First, move the sum of the two white dice \\nand resolve the space you land on (such as drawing a card, \\nbuying the property, paying rent, etc.). Then, one of two \\nthings will happen depending on whether or not there is still \\nproperty in the bank. \\nYES, there is property in the bank -Advance to the NEXT \\nproperty that the bank still holds and buy it if you wish. If you \\ndon\\'t want to buy this property, move to the space anyway \\nand put the property up for auction. \\nNO, there are no more properties in the bank - Advance to the \\nNOCT property on which you will owe another player money. \\nA few minor details: \\nOnly the white dice are used when determining if you rolled doubles. \\nDo not look at the Speed Die.')],\n",
       " 'question': 'Who wins the Monopoly?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for the chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "retriver = monopoly_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "setup = RunnableParallel(\n",
    "    context=retriver,\n",
    "    question = RunnablePassthrough()\n",
    ")\n",
    "\n",
    "setup.invoke(\"Who wins the Monopoly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To play Monopoly, you can choose to play by the classic rules for buying, renting, and selling properties or use the Speed Die to get into the action faster. When starting the game, hand out an extra $1,000 to each player, and do not use the Speed Die until you've landed on or passed over a certain point.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating chain\n",
    "\n",
    "chain = setup | prompt | model | output_parser\n",
    "\n",
    "chain.invoke(\"How to play Monopoly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I don't know case\n",
    "\n",
    "# chain.invoke(\"What is the meaning of life?\")\n",
    "chain.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To win Monopoly, you typically need to bankrupt your opponents by acquiring properties, charging rent, and making strategic decisions on buying and selling properties. Additionally, managing your money wisely, making smart trades, and investing in houses and hotels can also help you secure victory in the game.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How to win the Monopoly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n"
     ]
    }
   ],
   "source": [
    "emb = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "emb_q = emb.embed_query(\"Who is Mary's sister?\")\n",
    "\n",
    "print(f\"Embedding length: {len(emb_q)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
